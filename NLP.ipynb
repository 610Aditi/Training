{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzIhj3E+SXopTu4M9772W4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/610Aditi/Training/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic : NLP(**Natural Language Processing**)\n",
        "\n",
        "1) Tokenization :\n",
        "\n",
        "2) Embedding (Word2Vec , Glove)\n",
        "\n",
        "3) Bag-of-Words and TF-IDF\n",
        "\n",
        "**Natural Language Processing :** It is the branch of artifical intelligence that help to understand , interperte , generate human language.\n",
        "\n",
        "\n",
        "\n",
        "*  Without NLP\n",
        "*  With NLP\n",
        "\n",
        "**Application :**\n",
        "\n",
        "Search Engines ,Chatbots ,Email fittering ,Speed of Text ,Language translation ,grammer correction , Sentiment Analysis ,Text Samarization.\n",
        "\n",
        "Basic NLP Steps :  \n",
        "**Tokenization :**\n",
        "\n",
        "\n",
        "*   Remove Stopwords\n",
        "*   Stemming\n",
        "*   Vectorization\n",
        "*   Model Prediction\n",
        "\n",
        "**Basic Input -**\n",
        "\"NLP is the best branch of AI.\"\n",
        "\n",
        "**After Tokenizaton -**\n",
        "\"NLP\", \"is\",\"the\", \"best\" ,\"branch\", \"of\", \"AI.\""
      ],
      "metadata": {
        "id": "02AbdSUSBz-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK is a python library that is used for natuaral language processing\n",
        "import nltk\n",
        "nltk.download(\"All\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "data = \"NLP is the best branch of AI.\"\n",
        "Processed_data = word_tokenize(data)\n",
        "print(Processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "div-Qg-sGkbq",
        "outputId": "84b97fe3-9134-4e3b-8fd4-b687a985f1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'is', 'the', 'best', 'branch', 'of', 'AI', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading All: Package 'All' not found in index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = \"Curves can be represented by implicit, explicit, or parametric equations. Implicit equations cannot be used in computer graphics, explicit can, but not always in a convenient way. Parametric equations suit naturally the work with computers.\"\n",
        "data = \"He is working on google colab since 2004 .\"\n",
        "Processed_data = word_tokenize(data)\n",
        "print(Processed_data)\n",
        "print(len(Processed_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBySiBahHzPy",
        "outputId": "3bef60af-6eae-435c-fadb-d40c483eb3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'is', 'working', 'on', 'google', 'colab', 'since', '2004', '.']\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_sentence = []\n",
        "for w in Processed_data:\n",
        "    if w.lower() not in stop_words:\n",
        "        filtered_sentence.append(Processed_data)\n",
        "print(len(filtered_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIOMgqYBLLPc",
        "outputId": "b219a129-6966-4ede-8e89-a13f205d1a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming : Reduces words to there base root or forms.\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "TtkzwOFLMqkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stemmer = PorterStemmer()\n",
        "data1 = [Stemmer.stem(w) for w in Processed_data]\n",
        "print(data1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGqlKLxKQEro",
        "outputId": "a9acfbf3-e1aa-4996-c994-89fbec0c304d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'is', 'work', 'on', 'googl', 'colab', 'sinc', '2004', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization : It is a techineque that convert text into numeric vector\n",
        "# Types of Vectorization:\n",
        "# Bag of Words , TF IDF Vectorization ,Embedding\n",
        "#Bag of words : It count the words that how many times it appears in the whole document\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text = [\"I have NLP Books Books\",\"NLP Books In PDF Format\",\"NLP is important Branch of AI , ITs Important to have Knowledge of AI.\"]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "New_text = vector.fit_transform(text)\n",
        "print(vector.get_feature_names_out())\n",
        "print(New_text.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8aigR8eRTMz",
        "outputId": "a6b817c4-e29c-442d-a5f2-7d2ace919d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'books' 'branch' 'format' 'have' 'important' 'in' 'is' 'its'\n",
            " 'knowledge' 'nlp' 'of' 'pdf' 'to']\n",
            "[[0 2 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 1 0 0 0 1 0 1 0]\n",
            " [2 0 1 0 1 2 0 1 1 1 1 2 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF: TF is how frequently it appear in the document.\n",
        "# IDF : how rate it appear in the document.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "vector = tfidf.fit_transform(text)\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISuoMMElXNBK",
        "outputId": "32a47118-c694-4ff0-f000-570118241972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'books' 'branch' 'format' 'have' 'important' 'in' 'is' 'its'\n",
            " 'knowledge' 'nlp' 'of' 'pdf' 'to']\n",
            "[[0.         0.84492112 0.         0.         0.42246056 0.\n",
            "  0.         0.         0.         0.         0.32807831 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.38376993 0.         0.50461134 0.         0.\n",
            "  0.50461134 0.         0.         0.         0.29803159 0.\n",
            "  0.50461134 0.        ]\n",
            " [0.47236035 0.         0.23618018 0.         0.17962111 0.47236035\n",
            "  0.         0.23618018 0.23618018 0.23618018 0.13949182 0.47236035\n",
            "  0.         0.23618018]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58b06aae",
        "outputId": "ce4d2b6f-8db6-4946-c1e1-09f0726af729"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding (Word2Vec , Glove ): Word Embedding is mapped each word to a vector of real number.\n",
        "import gensim.downloader as api\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7p8L0blgYed",
        "outputId": "85e9f059-3850-442c-fa5f-7bb840c7b19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "KeyedVectors<vector_size=300, 3000000 keys>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector1 = word2vec_model[\"computer\"]\n",
        "print(vector1[:10])\n",
        "print(word2vec_model)\n",
        "\n",
        "simi = word2vec_model.most_similar(\"computer\")\n",
        "for i in simi:\n",
        "  print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlbfxWpqi_Dp",
        "outputId": "365fbe0a-daaa-4497-8403-ee4920fc4caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.10742188 -0.20117188  0.12304688  0.21191406 -0.09130859  0.21679688\n",
            " -0.13183594  0.08300781  0.20214844  0.04785156]\n",
            "KeyedVectors<vector_size=300, 3000000 keys>\n",
            "('computers', 0.7979379892349243)\n",
            "('laptop', 0.6640493273735046)\n",
            "('laptop_computer', 0.6548868417739868)\n",
            "('Computer', 0.647333562374115)\n",
            "('com_puter', 0.6082080006599426)\n",
            "('technician_Leonard_Luchko', 0.5662748217582703)\n",
            "('mainframes_minicomputers', 0.5617720484733582)\n",
            "('laptop_computers', 0.5585449934005737)\n",
            "('PC', 0.5539618730545044)\n",
            "('maker_Dell_DELL.O', 0.5519254207611084)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = api.load(\"glove-wiki-gigaword-50\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh3jVJ8WhAEt",
        "outputId": "52c85163-2e8e-4f79-c890-72794ba34071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector2 = model2[\"computer\"]\n",
        "print(vector2[:10])\n",
        "print(model2)\n",
        "\n",
        "simi2 = model2.most_similar(\"computer\")\n",
        "for j in simi2:\n",
        "  print(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaC8vwShjh_D",
        "outputId": "3f2c5413-9273-405c-979e-403e982ca2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.079084 -0.81504   1.7901    0.91653   0.10797  -0.55628  -0.84427\n",
            " -1.4951    0.13418   0.63627 ]\n",
            "KeyedVectors<vector_size=50, 400000 keys>\n",
            "('computers', 0.9165045022964478)\n",
            "('software', 0.8814992904663086)\n",
            "('technology', 0.852556049823761)\n",
            "('electronic', 0.812586784362793)\n",
            "('internet', 0.8060455322265625)\n",
            "('computing', 0.802603542804718)\n",
            "('devices', 0.8016185760498047)\n",
            "('digital', 0.7991793751716614)\n",
            "('applications', 0.7912740707397461)\n",
            "('pc', 0.7883159518241882)\n"
          ]
        }
      ]
    }
  ]
}