{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqaduY65/4SicrRQjeRX0Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/610Aditi/Training/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic : NLP(**Natural Language Processing**)\n",
        "\n",
        "1) Tokenization :\n",
        "\n",
        "2) Embedding (Word2Vec , Glove)\n",
        "\n",
        "3) Bag-of-Words and TF-IDF\n",
        "\n",
        "**Natural Language Processing :** It is the branch of artifical intelligence that help to understand , interperte , generate human language.\n",
        "\n",
        "\n",
        "\n",
        "*  Without NLP\n",
        "*  With NLP\n",
        "\n",
        "**Application :**\n",
        "\n",
        "Search Engines ,Chatbots ,Email fittering ,Speed of Text ,Language translation ,grammer correction , Sentiment Analysis ,Text Samarization.\n",
        "\n",
        "Basic NLP Steps :  \n",
        "**Tokenization :**\n",
        "\n",
        "\n",
        "*   Remove Stopwords\n",
        "*   Stemming\n",
        "*   Vectorization\n",
        "*   Model Prediction\n",
        "\n",
        "**Basic Input -**\n",
        "\"NLP is the best branch of AI.\"\n",
        "\n",
        "**After Tokenizaton -**\n",
        "\"NLP\", \"is\",\"the\", \"best\" ,\"branch\", \"of\", \"AI.\""
      ],
      "metadata": {
        "id": "02AbdSUSBz-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK is a python library that is used for natuaral language processing\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "except LookupError:\n",
        "    nltk.download(\"punkt\")\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "data = \"NLP is the best branch of AI.\"\n",
        "Processed_data = word_tokenize(data)\n",
        "print(Processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "div-Qg-sGkbq",
        "outputId": "f0d2c036-de07-4824-c618-5346019d4395"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'is', 'the', 'best', 'branch', 'of', 'AI', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = \"Curves can be represented by implicit, explicit, or parametric equations. Implicit equations cannot be used in computer graphics, explicit can, but not always in a convenient way. Parametric equations suit naturally the work with computers.\"\n",
        "data = \"He is working on google colab since 2004 .\"\n",
        "Processed_data = word_tokenize(data)\n",
        "print(Processed_data)\n",
        "print(len(Processed_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBySiBahHzPy",
        "outputId": "2c127ca1-989d-422b-de50-2589e4b490c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'is', 'working', 'on', 'google', 'colab', 'since', '2004', '.']\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_sentence = []\n",
        "for w in Processed_data:\n",
        "    if w.lower() not in stop_words:\n",
        "        filtered_sentence.append(Processed_data)\n",
        "print(len(filtered_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIOMgqYBLLPc",
        "outputId": "52d5cc4d-b8c9-4d7f-c739-6f08e55a0d05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming : Reduces words to there base root or forms.\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "TtkzwOFLMqkK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stemmer = PorterStemmer()\n",
        "data1 = [Stemmer.stem(w) for w in Processed_data]\n",
        "print(data1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGqlKLxKQEro",
        "outputId": "28c8e00c-b97e-45f7-d972-6cc9c815ddbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'is', 'work', 'on', 'googl', 'colab', 'sinc', '2004', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization : It is a techineque that convert text into numeric vector\n",
        "# Types of Vectorization:\n",
        "# Bag of Words , TF IDF Vectorization ,Embedding\n",
        "#Bag of words : It count the words that how many times it appears in the whole document\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text = [\"I have NLP Books Books\",\"NLP Books In PDF Format\",\"NLP is important Branch of AI , ITs Important to have Knowledge of AI.\"]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "New_text = vector.fit_transform(text)\n",
        "print(vector.get_feature_names_out())\n",
        "print(New_text.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8aigR8eRTMz",
        "outputId": "7ef59c75-41e6-4b32-c15b-7905a740a040"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'books' 'branch' 'format' 'have' 'important' 'in' 'is' 'its'\n",
            " 'knowledge' 'nlp' 'of' 'pdf' 'to']\n",
            "[[0 2 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 1 0 0 1 0 0 0 1 0 1 0]\n",
            " [2 0 1 0 1 2 0 1 1 1 1 2 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF: TF is how frequently it appear in the document.\n",
        "# IDF : how rate it appear in the document.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "vector = tfidf.fit_transform(text)\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISuoMMElXNBK",
        "outputId": "a75cef4d-d2aa-4070-81bb-fcd553f46a36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'books' 'branch' 'format' 'have' 'important' 'in' 'is' 'its'\n",
            " 'knowledge' 'nlp' 'of' 'pdf' 'to']\n",
            "[[0.         0.84492112 0.         0.         0.42246056 0.\n",
            "  0.         0.         0.         0.         0.32807831 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.38376993 0.         0.50461134 0.         0.\n",
            "  0.50461134 0.         0.         0.         0.29803159 0.\n",
            "  0.50461134 0.        ]\n",
            " [0.47236035 0.         0.23618018 0.         0.17962111 0.47236035\n",
            "  0.         0.23618018 0.23618018 0.23618018 0.13949182 0.47236035\n",
            "  0.         0.23618018]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58b06aae",
        "outputId": "747bac86-dac3-4ca8-f8af-94ad0cc3d735"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding (Word2Vec , Glove ): Word Embedding is mapped each word to a vector of real number.\n",
        "import gensim.downloader as api\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7p8L0blgYed",
        "outputId": "66147b31-71fe-46ea-c8da-43c4469fe76d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector1 = word2vec_model[\"computer\"]\n",
        "print(vector1[:10])\n",
        "print(word2vec_model)\n",
        "\n",
        "simi = word2vec_model.most_similar(\"computer\")\n",
        "for i in simi:\n",
        "  print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlbfxWpqi_Dp",
        "outputId": "b7ff32cb-27fd-4d45-b2de-cd27c276f4bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.10742188 -0.20117188  0.12304688  0.21191406 -0.09130859  0.21679688\n",
            " -0.13183594  0.08300781  0.20214844  0.04785156]\n",
            "KeyedVectors<vector_size=300, 3000000 keys>\n",
            "('computers', 0.7979379892349243)\n",
            "('laptop', 0.6640493273735046)\n",
            "('laptop_computer', 0.6548868417739868)\n",
            "('Computer', 0.647333562374115)\n",
            "('com_puter', 0.6082080006599426)\n",
            "('technician_Leonard_Luchko', 0.5662748217582703)\n",
            "('mainframes_minicomputers', 0.5617720484733582)\n",
            "('laptop_computers', 0.5585449934005737)\n",
            "('PC', 0.5539618730545044)\n",
            "('maker_Dell_DELL.O', 0.5519254207611084)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = api.load(\"glove-wiki-gigaword-50\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh3jVJ8WhAEt",
        "outputId": "b1e9c5af-1e76-4ed9-ae18-eda6cd130a2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector2 = model2[\"computer\"]\n",
        "print(vector2[:10])\n",
        "print(model2)\n",
        "\n",
        "simi2 = model2.most_similar(\"computer\")\n",
        "for j in simi2:\n",
        "  print(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaC8vwShjh_D",
        "outputId": "7f1e3251-c26a-43d1-b8de-f47f7935b594"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.079084 -0.81504   1.7901    0.91653   0.10797  -0.55628  -0.84427\n",
            " -1.4951    0.13418   0.63627 ]\n",
            "KeyedVectors<vector_size=50, 400000 keys>\n",
            "('computers', 0.9165045022964478)\n",
            "('software', 0.8814992904663086)\n",
            "('technology', 0.852556049823761)\n",
            "('electronic', 0.812586784362793)\n",
            "('internet', 0.8060455322265625)\n",
            "('computing', 0.802603542804718)\n",
            "('devices', 0.8016185760498047)\n",
            "('digital', 0.7991793751716614)\n",
            "('applications', 0.7912740707397461)\n",
            "('pc', 0.7883159518241882)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Attention** is a technique that allow a model to focus on specific words in a sentence  when performing a task.\n",
        "\n",
        "** Why we need Attention **\n",
        "\n",
        "Attention leads the model to attend the sequence even for apart of words.\n",
        "\n",
        "**Types :**\n",
        "\n",
        "\n",
        "*   Self Attention\n",
        "*   Global Attention\n",
        "*   Local Attention\n",
        "*   Multihead Attention\n",
        "\n",
        "**Self Attention :**\n",
        "\n",
        "Q : what i want to know (queries).\n",
        "\n",
        "K : what each words decode/effect.\n",
        "\n",
        "V : word representation.\n"
      ],
      "metadata": {
        "id": "RP1bz8vWTZdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az1QB9gwXzBF",
        "outputId": "ec46bbe3-393b-4fc0-8a3e-8f3bd81e068b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as fn\n",
        "\n",
        "text = [\"The\",\"Man\",\"Work\"]\n",
        "e_d = 8\n",
        "words_to_index = {w:i for i,w in enumerate(text)}\n",
        "index_to_words = {i:w for i,w in enumerate(text)}\n",
        "\n"
      ],
      "metadata": {
        "id": "8HTmDPstYBwg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18YgjENFZF4R",
        "outputId": "c4595ceb-a1f5-42a9-f668-eab0e49e4db8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The': 0, 'Man': 1, 'Work': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(index_to_words)\n",
        "idx_words = torch.tensor([words_to_index[w] for w in text],dtype=torch.long)\n",
        "print(idx_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOKSel3_ZMj5",
        "outputId": "4ae17d35-aad0-4fd9-f159-1b161d922908"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(num_embeddings=len(words_to_index),embedding_dim=e_d)\n",
        "\n"
      ],
      "metadata": {
        "id": "VS2VV7ygZRVD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeded= embed(idx_words)\n",
        "embeded = embeded.unsqueeze(0)\n",
        "print(embeded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNyhPj4XbLZt",
        "outputId": "6b498b08-dee6-4c9f-d67f-95e91dcca2aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.9677, -0.6863, -0.3008, -0.4824, -1.2882, -1.9787, -0.6491,\n",
            "          -1.9602],\n",
            "         [ 1.0126,  0.8047,  0.7653,  0.7078,  0.7379,  0.1020, -1.6547,\n",
            "          -0.2611],\n",
            "         [ 0.4364,  0.2187,  0.3832,  2.1965, -1.0348, -0.8579, -0.4617,\n",
            "          -0.3447]]], grad_fn=<UnsqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_head = 2\n",
        "multi_head = nn.MultiheadAttention(embed_dim=e_d,num_heads=num_head,batch_first=True)"
      ],
      "metadata": {
        "id": "tu-bLI8Tbtku"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multi_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aSdumUida4I",
        "outputId": "e63ba215-5b8a-49fc-fed0-e658b7879060"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiheadAttention(\n",
            "  (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_output,a_weights=multi_head(embeded,embeded,embeded)\n",
        "print(a_output)\n",
        "print(a_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA7UR5JtdldH",
        "outputId": "2fc1685f-3c95-4970-b117-5265441bb197"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1495, -0.2471, -0.1526, -0.0490, -0.0299, -0.2354,  0.1486,\n",
            "           0.2971],\n",
            "         [ 0.3781, -0.1267, -0.1950, -0.0320, -0.2279, -0.3994, -0.1131,\n",
            "           0.1583],\n",
            "         [ 0.0808, -0.2978, -0.1151, -0.0271,  0.0047, -0.2250,  0.1959,\n",
            "           0.3272]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.4008, 0.2672, 0.3320],\n",
            "         [0.5605, 0.2187, 0.2209],\n",
            "         [0.3122, 0.2513, 0.4365]]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_weights.squeeze(0).detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-t28a_xd9B1",
        "outputId": "30dd5a26-cf72-48c9-f362-3b9f72f52b9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4008, 0.2672, 0.3320],\n",
              "        [0.5605, 0.2187, 0.2209],\n",
              "        [0.3122, 0.2513, 0.4365]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_output.squeeze(0).detach()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb6eAgHmfOo6",
        "outputId": "a81e3400-f67b-459f-d13d-e9d01cba400c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1495, -0.2471, -0.1526, -0.0490, -0.0299, -0.2354,  0.1486,  0.2971],\n",
              "        [ 0.3781, -0.1267, -0.1950, -0.0320, -0.2279, -0.3994, -0.1131,  0.1583],\n",
              "        [ 0.0808, -0.2978, -0.1151, -0.0271,  0.0047, -0.2250,  0.1959,  0.3272]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformers**:it follows a encoder-decoder design.Also called **Hugging Phase**.\n",
        "\n",
        "Encoder basically reads the input sentence and build the relation.(BERT Models)\n",
        "\n",
        "Decoder basically takes the representation as a output.(GPT Models)\n"
      ],
      "metadata": {
        "id": "SPrGdr5HiPgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\"The Man Works\"\n",
        "!pip install transformers sentecepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSysT54sfyWJ",
        "outputId": "a7a0be64-2113-4198-8592-83615b624ca7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sentecepiece (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sentecepiece\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer"
      ],
      "metadata": {
        "id": "_k4sRC0Flrv_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "tok = MarianTokenizer.from_pretrained(model)\n",
        "models = MarianMTModel.from_pretrained(model)\n",
        "\n",
        "input_text = [\"The Man Works\"]\n",
        "token_input = tok(input_text,return_tensors=\"pt\",padding = True,Truncation=True)\n",
        "\n",
        "print(token_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2njGgTl-N6",
        "outputId": "9c72ced9-ed59-400c-cd10-b5268cef018c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'Truncation': True} not recognized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   81,  4221, 24741,     0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate = models.generate(**token_input)"
      ],
      "metadata": {
        "id": "vC0RSxx5oF3C"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate"
      ],
      "metadata": {
        "id": "f59jqATcotht",
        "outputId": "7d871735-9655-4d13-f52d-69192111bd2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[61949,   720,   182,   161,     5,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "output = tok.batch_decode(translate,skip_special_tokens=True)\n",
        "output"
      ],
      "metadata": {
        "id": "ypROjK6gpwC6",
        "outputId": "c43a0a6a-1f84-4213-b481-bca32474fd40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मनुष्य काम करता है']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  convert model into API\n"
      ],
      "metadata": {
        "id": "eXU_qwm4qCe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library :**\n",
        "\n",
        "numpy ,pandas,seaborn ,sklearn ,pytouch ,tensorflow-keras\n",
        ",NLTHK,transformer - hugging phase library ,gensim,langpedect,open_cv,pillow(PIL), touch vision ,Fast AI -used in deeplearning"
      ],
      "metadata": {
        "id": "dAXW7TeZsVOw"
      }
    }
  ]
}